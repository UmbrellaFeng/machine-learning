机器学习笔记（1）
==========
## 评估方法 

### 留出法
将数据集D划分为两个互斥的集合，其中一个作为训练集S，另一个为测试集T，即

<a href="https://www.codecogs.com/eqnedit.php?latex=D=S&space;\cup&space;T,S&space;\cap&space;T=\emptyset" target="_blank"><img src="https://latex.codecogs.com/gif.latex?D=S&space;\cup&space;T,S&space;\cap&space;T=\emptyset" title="D=S \cup T,S \cap T=\emptyset" /></a>

需要注意的是，训练/测试集的划分要尽可能保持数据分布的一致性，即所谓采用__分层抽样__。

另一个需要注意的是，由于不同的划分，仍有可能导致估计结果不稳定可靠。一般采用__若干次随机划分__，__重复进行实验取平均__得到实验效果。

### 交叉验证法
将数据集D划分为k个大小相似的互斥子集，即

<a href="https://www.codecogs.com/eqnedit.php?latex=D=D_1&space;\cup&space;D_2&space;\cup&space;D_3&space;\cup&space;...&space;\cup&space;D_k,D_i&space;\cap&space;D_j&space;=\emptyset" target="_blank"><img src="https://latex.codecogs.com/gif.latex?D=D_1&space;\cup&space;D_2&space;\cup&space;D_3&space;\cup&space;...&space;\cup&space;D_k,D_i&space;\cap&space;D_j&space;=\emptyset" title="D=D_1 \cup D_2 \cup D_3 \cup ... \cup D_k,D_i \cap D_j =\emptyset" /></a>

每次用k-1个子集的并集作为训练集，余下的一个作为测试集，这样就可进行k组测试。通常把这样的交叉验证成为__k折交叉验证__

### 自助法

* 以自主采样法为基础
* 改变了数据集的分布，引入了估计误差

在包含m个样本的数据集D中，随机且放回的采样m个数据，生成训练集D'。此时，样本在m次采样中始终不被采到的概率为

<a href="https://www.codecogs.com/eqnedit.php?latex=(1-\frac{1}{m})^{m}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?(1-\frac{1}{m})^{m}" title="(1-\frac{1}{m})^{m}" /></a>

取极限得到

<a href="https://www.codecogs.com/eqnedit.php?latex=\lim_{m\rightarrow&space;\infty}(1-\frac{1}{m})^{m}=\frac{1}{e}&space;\approx&space;0.368" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\lim_{m\rightarrow&space;\infty}(1-\frac{1}{m})^{m}=\frac{1}{e}&space;\approx&space;0.368" title="\lim_{m\rightarrow \infty}(1-\frac{1}{m})^{m}=\frac{1}{e} \approx 0.368" /></a>

通过自助采样，初始训练集D中有36.8%的样本不在D'中。以D作为测试集测试，即为__自助法__，测试结果亦称__包外估计__。

## 性能度量
